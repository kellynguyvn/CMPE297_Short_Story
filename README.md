# Short Story Assignment
Submission by Kelly Nguyen for CMPE 297: Special Topics
-----
## Abstract
This short story assignment illuminates the comprehensive analysis conducted in the seminal paper “A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions,” authored by Lei Huang and colleagues from the prestigious ACM Transactions on Information Systems. Presented with acuity at a prominent AI conference, the paper meticulously explores the phenomena of hallucinations in large language models (LLMs) such as GPT-4, which, while pushing the boundaries of AI’s capabilities, often generate plausible yet factually incorrect or misleading content.
## Deliverables
### Deciphering Hallucinations: A Technical Deep Dive from a Comprehensive Survey on LLMs
[Medium Article](https://medium.com/@kelly.nguyen01/deciphering-hallucinations-a-technical-deep-dive-from-a-comprehensive-survey-on-llms-9930158d9d4d)
### Presentation Slides
[Slideshare Link](https://www.slideshare.net/slideshow/hallucination-in-large-language-models-principles-taxonomy-challenges-and-open-questions-pdf/273850009)
### Video Presentation
[Youtube Link](https://www.youtube.com/watch?v=I5mbisCqH80)

## References
[Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, and Ting Liu. 2024. A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions. ACM Transactions on Information Systems 1, 1, Article 1 (January 2024), 58 pages.](https://arxiv.org/pdf/2311.05232)
